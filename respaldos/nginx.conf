desarrollo: # esto ayuda al manejo de carga de solicitudes que tendran nuestors microservicio
# a esto se le llama balanceo de carga. balanceo de carga.
worker_processes 4;

events {
    worker_connections 1024;
}

http {

    # aqui configurar el tipo de compresion o archivos
    #gzip on;
    #gzip_types text/plain application/xml application/json;
    #gzip_min_length 1000;
    
    # Definimos el bloque 'upstream' que agrupa los servidores backend
    # Este bloque crea un pool de servidores para balanceo de carga
    upstream python-service-desarrollo {

        # cuando haga una peticion siempre ira a un servidor es decir a el frontend
        #eso realiza el ip_hash
        #ip_hash
        # Aquí estás definiendo una única instancia del microservicio en Python.
        # Si quisieras balancear entre varias instancias, podrías añadir más servidores aquí.
        server 127.0.0.1:3000;
    }

    upstream nestjs-desarrollo {
        
        #ip_hash
        # Similar al bloque anterior, este define el backend del microservicio NestJS.
        # De nuevo, si tuvieras varias instancias de NestJS, podrías añadirlas aquí.
        server 127.0.0.1:3001;
    }




        # Configuración del bloque 'server' para manejar las solicitudes entrantes en el puerto 80
    server {
            
            #AQUI PUEDEN IR SSL PARA EL CIFRADO DE DATOS https configurar

            #configurar cabecera http especificar algun tipo de contenido o configuracion 
            #add_header X-Frame-Options "SAMEORIGIN"
            #add_header X-Content-Type-Options "nosniff"
            #add_header X-XSS-Protection "1; mode=block"

            # Este es el puerto por defecto en el que Nginx escucha (HTTP)
            listen 80;
            server_name frontend-desarrollo;



                # Este bloque gestiona las solicitudes que van hacia el frontend
            location / {


            # Configuración del frontend para desarrollo
            root /usr/share/nginx/html/proyecto-frontApp;
            index index.html index.htm;
            try_files $uri $uri/ /index.html =400;
                        
            # Se redirige todo el tráfico de la raíz al frontend que corre en el puerto 3003
            proxy_pass http://frontend-desarrollo;
            
            # Ruta al archivo de contraseñas
            auth_basic "Restricted Area";
            auth_basic_user_file /etc/nginx/.htpasswd;  
            
            # Usamos HTTP/1.1 para asegurarnos de que las conexiones sean eficientes.
            proxy_http_version 1.1;

            # Configuraciones específicas para WebSockets (útiles si usas WebSockets en tu frontend).
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';

            # Envía el encabezado original del host para que los servidores backend lo vean como se espera.
            proxy_set_header Host $host;

            # Evita que el proxy almacene en caché las solicitudes, útil para evitar inconsistencias en la actualización.
            proxy_cache_bypass $http_upgrade;

            
            
            
            proxy_read_timeout 60s;
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;

            #aqui asignamos la configuracion del buffering para cuando existan envios de datos muy grandes
            #proxy_buffering on;
            #proxy_buffers 16 34k;
            #proxy_buffer_size 64k;

            

            }


            # Aquí podrías añadir otros bloques 'location' si quisieras manejar rutas específicas (ECHO)
            # Redirige todas las solicitudes que comiencen con /nestjs al microservicio de NestJS
            location /nestjs-desarrollo/ {
                #todo lo que me llege en este servidor se conviarta en barra
                rewrite ^/nestjs-desarrollo(.*) /$1 break;

                # Reemplaza con el nombre de tu servicio de NestJS
                proxy_pass http://nestjs-desarrollo;  
                
                # Ruta al archivo de contraseñas
                #auth_basic "Restricted Access";
                #auth_basic_user_file /etc/nginx/.htpasswd;

                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;

                proxy_read_timeout 60s;
                proxy_connect_timeout 60s;
                proxy_send_timeout 60s;
                
                #aqui asignamos la configuracion del buffering para cuando existan envios de datos muy grandes
                #proxy_buffering on;
                #proxy_buffers 16 34k;
                #proxy_buffer_size 64k;
            }

            

            # Redirige todas las solicitudes que comiencen con /python-service al microservicio de Python
            # en el archivo docker-compose.ylm estan los nombres de los servicios, entonces las peticiones iran 
            # a ese servicio
            location /python-service-desarrollo/ {
                #todo lo que me llege en este servidor se conviarta en barra
                rewrite ^/python-service-desarrollo(.*) /$1 break;

                proxy_pass http://python-service-desarrollo;  # Reemplaza con el nombre de tu servicio de Python

                # Ruta al archivo de contraseñas
                #auth_basic "Restricted Access";
                #auth_basic_user_file /etc/nginx/.htpasswd;

                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;



                proxy_read_timeout 60s;
                proxy_connect_timeout 60s;
                proxy_send_timeout 60s;
                #aqui asignamos la configuracion del buffering para cuando existan envios de datos muy grandes
                #proxy_buffering on;
                #proxy_buffers 16 34k;
                #proxy_buffer_size 64k;
            }
        

            # que apunten directamente a tus microservicios.

        
    }


    

}, produccion:  # esto ayuda al manejo de carga de solicitudes que tendran nuestors microservicio
# a esto se le llama balanceo de carga. balanceo de carga.
worker_processes 4;

events {
    worker_connections 1024;
}

http {

    # aqui configurar el tipo de compresion o archivos
    #gzip on;
    #gzip_types text/plain application/xml application/json;
    #gzip_min_length 1000;
    

    upstream python-service-produccion {

        # cuando haga una peticion siempre ira a un servidor es decir a el frontend
        #eso realiza el ip_hash
        #ip_hash
        # Aquí estás definiendo una única instancia del microservicio en Python.
        # Si quisieras balancear entre varias instancias, podrías añadir más servidores aquí.
        server 127.0.0.1:4000;
    }

    upstream nestjs-produccion {
        
        #ip_hash
        # Similar al bloque anterior, este define el backend del microservicio NestJS.
        # De nuevo, si tuvieras varias instancias de NestJS, podrías añadirlas aquí.
        server 127.0.0.1:4001;
    }




    server {
            
            #AQUI PUEDEN IR SSL PARA EL CIFRADO DE DATOS https configurar

            #configurar cabecera http especificar algun tipo de contenido o configuracion 
            #add_header X-Frame-Options "SAMEORIGIN"
            #add_header X-Content-Type-Options "nosniff"
            #add_header X-XSS-Protection "1; mode=block"

            # Este es el puerto por defecto en el que Nginx escucha (HTTP)
            listen 81;
            server_name frontend-produccion;



            # Este bloque gestiona las solicitudes que van hacia el frontend
            location / {
                
            # Configuración del frontend para producción
            root /usr/share/nginx/html/proyecto-frontApp;
            index index.html index.htm;
            try_files $uri $uri/ /index.html =400;

            # Se redirige todo el tráfico de la raíz al frontend que corre en el puerto 4003
            proxy_pass http://frontend-produccion;
            
            # Ruta al archivo de contraseñas
            auth_basic "Restricted Area";
            auth_basic_user_file /etc/nginx/.htpasswd;  
            
            # Usamos HTTP/1.1 para asegurarnos de que las conexiones sean eficientes.
            proxy_http_version 1.1;

            # Configuraciones específicas para WebSockets (útiles si usas WebSockets en tu frontend).
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';

            # Envía el encabezado original del host para que los servidores backend lo vean como se espera.
            proxy_set_header Host $host;

            # Evita que el proxy almacene en caché las solicitudes, útil para evitar inconsistencias en la actualización.
            proxy_cache_bypass $http_upgrade;

            
            
            
            proxy_read_timeout 60s;
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;

            #aqui asignamos la configuracion del buffering para cuando existan envios de datos muy grandes
            #proxy_buffering on;
            #proxy_buffers 16 34k;
            #proxy_buffer_size 64k;

            

            }


            # Aquí podrías añadir otros bloques 'location' si quisieras manejar rutas específicas (ECHO)
            # Redirige todas las solicitudes que comiencen con /nestjs al microservicio de NestJS
            location /nestjs-produccion/ {
                #todo lo que me llege en este servidor se conviarta en barra
                rewrite ^/nestjs-produccion(.*) /$1 break;

                # Reemplaza con el nombre de tu servicio de NestJS
                proxy_pass http://nestjs-produccion;  
                
                # Ruta al archivo de contraseñas
                #auth_basic "Restricted Access";
                #auth_basic_user_file /etc/nginx/.htpasswd;

                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;

                proxy_read_timeout 60s;
                proxy_connect_timeout 60s;
                proxy_send_timeout 60s;
                
                #aqui asignamos la configuracion del buffering para cuando existan envios de datos muy grandes
                #proxy_buffering on;
                #proxy_buffers 16 34k;
                #proxy_buffer_size 64k;
            }

            

            # Redirige todas las solicitudes que comiencen con /python-service al microservicio de Python
            # en el archivo docker-compose.ylm estan los nombres de los servicios, entonces las peticiones iran 
            # a ese servicio
            location /python-service-produccion/ {
                #todo lo que me llege en este servidor se conviarta en barra
                rewrite ^/python-service-produccion(.*) /$1 break;

                proxy_pass http://python-service-produccion;  # Reemplaza con el nombre de tu servicio de Python

                # Ruta al archivo de contraseñas
                #auth_basic "Restricted Access";
                #auth_basic_user_file /etc/nginx/.htpasswd;

                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;



                proxy_read_timeout 60s;
                proxy_connect_timeout 60s;
                proxy_send_timeout 60s;
                #aqui asignamos la configuracion del buffering para cuando existan envios de datos muy grandes
                #proxy_buffering on;
                #proxy_buffers 16 34k;
                #proxy_buffer_size 64k;
            }
        

            # que apunten directamente a tus microservicios.

        
    }

}